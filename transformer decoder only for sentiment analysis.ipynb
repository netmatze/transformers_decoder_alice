{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d19def7-9f7f-4d70-9a05-4628de8df14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c28c56-422a-4067-abb8-de31c231cc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c1ce2f5-9fa2-49a3-b8f1-c2835bfaae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(start=0, end=max_len, step=1).float().unsqueeze(1)\n",
    "        embedding_index = torch.arange(start=0, end=d_model, step=2).float()\n",
    "        div_term = 1 / torch.tensor(10000.0)**(embedding_index / d_model)\n",
    "        #print(div_term)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe',pe)\n",
    "\n",
    "    def forward(self, word_embeddings):\n",
    "        pe_temp = self.pe[:word_embeddings.size(0), :]\n",
    "        pe_temp_expanded = pe_temp.unsqueeze(1)\n",
    "        #print(f\"word_embeddings.shape: {word_embeddings.shape}, self.pe.shape: {pe_temp_expanded.shape}, \")\n",
    "        return word_embeddings + pe_temp_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ec0c54-2111-4270-ae32-f2f744dc69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model=2):\n",
    "        super().__init__()\n",
    "        self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "        self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "        self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "        self.row_dim = 0\n",
    "        self.col_dim = 1\n",
    "\n",
    "    def forward(self, encodings, mask=None):\n",
    "        q = self.W_q(encodings)\n",
    "        k = self.W_k(encodings)\n",
    "        v = self.W_v(encodings)\n",
    "\n",
    "        # Ensure k has the same shape as q before transpose\n",
    "        assert k.shape == q.shape\n",
    "\n",
    "        # Transpose k to align with q for dot product\n",
    "        k_transposed = k.transpose(-1, -2)\n",
    "\n",
    "        # Check shapes\n",
    "        #print(\"Shape of q:\", q.shape)  # [1, 5, 2]\n",
    "        #print(\"Shape of k_transposed:\", k_transposed.shape)  # [1, 2, 5]\n",
    "        sims = torch.matmul(q, k_transposed)\n",
    "        scaled_sims = sims / torch.tensor(k.size(1)**0.5)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.to(device)\n",
    "            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n",
    "\n",
    "        attention_percents = F.softmax(scaled_sims)\n",
    "        attention_scores = torch.matmul(attention_percents, v)\n",
    "        return attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec861184-6680-4392-ac7d-09c414c36b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model=2,heads=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.W_qs = []\n",
    "        self.W_ks = []\n",
    "        self.W_vs = []\n",
    "\n",
    "        for index in range(heads):\n",
    "            W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "            W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "            W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "\n",
    "            self.W_qs.append(W_q)\n",
    "            self.W_ks.append(W_k)\n",
    "            self.W_vs.append(W_v)\n",
    "\n",
    "        self.unify_heads = nn.Linear(d_model * heads, d_model)\n",
    "\n",
    "        self.row_dim = 0\n",
    "        self.col_dim = 1\n",
    "        self.heads = heads\n",
    "\n",
    "    def forward(self, encodings, mask=None):\n",
    "        attentionscores = []\n",
    "        #encodings.to(device)\n",
    "        for index in range(self.heads):\n",
    "            W_q = self.W_qs[index].to(device)\n",
    "            W_k = self.W_ks[index].to(device)\n",
    "            W_v = self.W_vs[index].to(device)\n",
    "\n",
    "            q = W_q(encodings.to(device))\n",
    "            k = W_k(encodings.to(device))\n",
    "            v = W_v(encodings.to(device))\n",
    "\n",
    "            k_transposed = k.transpose(-1, -2)\n",
    "            sims = torch.matmul(q, k_transposed)\n",
    "            scaled_sims = sims / torch.tensor(k.size(1)**0.5)\n",
    "\n",
    "            if mask is not None:\n",
    "                mask = mask.to(device)\n",
    "                scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n",
    "\n",
    "            attention_percents = F.softmax(scaled_sims)\n",
    "            attention_scores = torch.matmul(attention_percents, v)\n",
    "            attentionscores.append(attention_scores)\n",
    "\n",
    "        combined_attention_scores = torch.cat(attentionscores, dim=-1)\n",
    "        combined_output = self.unify_heads(combined_attention_scores)\n",
    "\n",
    "        return combined_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cffbad23-6807-4ba8-a08c-4eca84fadc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, num_tokens, using_mask=True):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.self_attention = MultiHeadAttention(d_model=d_model, heads=num_heads)\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_layer = nn.Linear(in_features=d_model, out_features=d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.fc_layer2 = nn.Linear(in_features=d_model, out_features=d_model)\n",
    "        dropout=0.1\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.using_mask = using_mask\n",
    "\n",
    "    def forward(self, position_encoded, mask=None):\n",
    "        if self.using_mask:\n",
    "            self_attention_values = self.self_attention(position_encoded, mask=mask)\n",
    "        else:\n",
    "            self_attention_values = self.self_attention(position_encoded)\n",
    "\n",
    "        residual_connection_values = position_encoded + self_attention_values\n",
    "        normalized_values1 = self.layer_norm1(residual_connection_values)\n",
    "\n",
    "        fc_layer_output_relu = self.relu(self.fc_layer(normalized_values1))\n",
    "        #fc_layer_output_dropout = self.dropout(fc_layer_output_relu)\n",
    "        #fc_layer_output = self.fc_layer2(fc_layer_output_dropout)\n",
    "        #final_output = self.layer_norm2(normalized_values1 + fc_layer_output)\n",
    "        #fc_layer_output = self.fc_layer2(self.dropout(self.relu(self.fc_layer(normalized_values1))))\n",
    "        #return final_output\n",
    "        #fc_layer_output = self.fc_layer(normalized_values1)\n",
    "        fc_layer_output = self.relu(self.fc_layer(normalized_values1))\n",
    "        return fc_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d29de067-4b46-4898-9c10-08c1a5957135",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderOnlyTransformerBlockTransformer(nn.Module):\n",
    "    def __init__(self, num_tokens, d_model, max_len, using_mask=True):\n",
    "        super(DecoderOnlyTransformerBlockTransformer, self).__init__()\n",
    "        self.number_heads = 8\n",
    "        self.we = nn.Embedding(num_embeddings=num_tokens, embedding_dim=d_model)\n",
    "        self.pe = PositionalEncoding(d_model=d_model, max_len=max_len)\n",
    "        self.decoder_block1 = DecoderBlock(d_model=d_model, num_heads=self.number_heads, num_tokens=num_tokens, using_mask=using_mask)\n",
    "        #self.decoder_block2 = DecoderBlock(d_model=d_model, num_heads=self.number_heads, num_tokens=num_tokens, using_mask=using_mask)\n",
    "        #self.decoder_block3 = DecoderBlock(d_model=d_model, num_heads=self.number_heads, num_tokens=num_tokens, using_mask=using_mask)\n",
    "        #self.decoder_block4 = DecoderBlock(d_model=d_model, num_heads=self.number_heads, num_tokens=num_tokens, using_mask=using_mask)\n",
    "        #self.decoder_block5 = DecoderBlock(d_model=d_model, num_heads=self.number_heads, num_tokens=num_tokens, using_mask=using_mask)\n",
    "        #self.decoder_block6 = DecoderBlock(d_model=d_model, num_heads=self.number_heads, num_tokens=num_tokens, using_mask=using_mask)\n",
    "\n",
    "        self.fc_layer = nn.Linear(in_features=d_model, out_features=1)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, token_ids):\n",
    "        word_embeddings = self.we(token_ids)\n",
    "        position_encoded = self.pe(word_embeddings)\n",
    "\n",
    "        if self.decoder_block1.using_mask:\n",
    "            mask_ones = torch.ones((token_ids.size(dim=1), token_ids.size(dim=1)))\n",
    "            mask = torch.tril(mask_ones)\n",
    "            mask = mask == 0\n",
    "        else:\n",
    "            mask = None\n",
    "\n",
    "        output_block1 = self.decoder_block1(position_encoded, mask=mask)\n",
    "        #output_block2 = self.decoder_block2(output_block1, mask=mask)\n",
    "        #output_block3 = self.decoder_block3(output_block2, mask=mask)\n",
    "        #output_block4 = self.decoder_block4(output_block3, mask=mask)\n",
    "        #output_block5 = self.decoder_block5(output_block4, mask=mask)\n",
    "        #output_block6 = self.decoder_block6(output_block5, mask=mask)\n",
    "\n",
    "        fc_layer_output = self.fc_layer(output_block1)\n",
    "        #print(f\"fc_layer_output.shape: {fc_layer_output.shape}\")\n",
    "\n",
    "        return fc_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33d921e5-a0aa-460d-9649-4402147f9806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('./datasets/IMDBDataset.csv')\n",
    "df = df.head(4096)\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07872ed0-3e3a-47c2-9ac5-30c2e77a11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(texts, min_freq=1):\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        words = text.lower().split()\n",
    "        counter.update(words)\n",
    "    # Only keep words with a frequency greater than min_freq\n",
    "    vocab = {word: idx + 2 for idx, (word, freq) in enumerate(counter.items()) if freq >= min_freq}\n",
    "    vocab['<PAD>'] = 0\n",
    "    vocab['<UNK>'] = 1\n",
    "    return vocab\n",
    "\n",
    "# Build vocabulary from reviews\n",
    "vocab = build_vocab(df['review'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b202a655-5887-4c8b-ac0b-ed78f202f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, vocab):\n",
    "    return [vocab.get(word, vocab['<UNK>']) for word in text.lower().split()]\n",
    "\n",
    "df['tokenized_review'] = df['review'].apply(lambda x: tokenize(x, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8d9958b-00b0-47bd-bdb9-8e42d04f57f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the sentiment labels\n",
    "le = LabelEncoder()\n",
    "df['sentiment'] = le.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07e9ced6-3070-4bc9-a2cf-d4b7f15c22eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, reviews, sentiments, vocab, max_length=100):\n",
    "        self.reviews = reviews\n",
    "        self.sentiments = sentiments\n",
    "        self.vocab = vocab\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = self.reviews[idx]\n",
    "        sentiment = self.sentiments[idx]\n",
    "\n",
    "        # Pad or truncate the review to max_length\n",
    "        if len(review) > self.max_length:\n",
    "            review = review[:self.max_length]\n",
    "        else:\n",
    "            review = review + [self.vocab['<PAD>']] * (self.max_length - len(review))\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(review, dtype=torch.long),\n",
    "            'label': torch.tensor(sentiment, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83c75230-d6dd-4d48-8041-397f44c3b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Create the dataset\n",
    "dataset = IMDBDataset(df['tokenized_review'].tolist(), df['sentiment'].tolist(), vocab)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18ad950c-7e33-4640-97e9-e8ba4ed3ca06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tokens shape: torch.Size([32, 100])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    input_tokens = batch['input_ids']\n",
    "    labels = batch['label']\n",
    "    print(f\"Input Tokens shape: {input_tokens.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "862b4474-a4fa-485b-9863-64dc7b27f793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequence:\n",
      "tensor([[  535,    36, 66092,  ...,   708,   228,   776],\n",
      "        [ 5114, 27542, 30346,  ...,     4, 27908,   196],\n",
      "        [75035,  3219,    22,  ...,   752,    82,   736],\n",
      "        ...,\n",
      "        [   23,    24,     2,  ...,    65,   395,   647],\n",
      "        [   54,  4155,     3,  ...,  3194,    46,     4],\n",
      "        [  147,   225,   802,  ...,    40,  1072,   170]])\n",
      "Target Sequence:\n",
      "tensor([0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0])\n",
      "80921\n",
      "80921\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the DataLoader\n",
    "for batch in train_dataloader:\n",
    "    input_seq = batch['input_ids']\n",
    "    target_seq = batch['label']\n",
    "    \n",
    "    print(\"Input Sequence:\")\n",
    "    print(input_seq)  # (batch_size, sequence_length)\n",
    "    \n",
    "    print(\"Target Sequence:\")\n",
    "    print(target_seq)  # (batch_size,)\n",
    "    \n",
    "    # Example break to print only one batch\n",
    "    break\n",
    "\n",
    "token_to_id = dataset.vocab\n",
    "print(len(token_to_id))\n",
    "id_to_token = dict(map(reversed, token_to_id.items()))\n",
    "print(len(id_to_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b779be76-708f-499d-ab17-d7697956529f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mscho\\AppData\\Local\\Temp\\ipykernel_21296\\1332413963.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attention_percents = F.softmax(scaled_sims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 0.11577490750110768\n",
      "Epoch 1, Train Loss: 3.115377515473122e-05\n",
      "Epoch 2, Train Loss: 1.8296417652931227e-05\n",
      "Epoch 3, Train Loss: 1.2198669145606408e-05\n",
      "Epoch 4, Train Loss: 8.712462092525472e-06\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "max_len = 100\n",
    "token_to_id = dataset.vocab\n",
    "#print(token_to_id)\n",
    "id_to_token = dict(map(reversed, token_to_id.items()))\n",
    "print(len(token_to_id))\n",
    "\n",
    "#dimension_model = 768\n",
    "dimension_model = 256\n",
    "\n",
    "transformer_model = DecoderOnlyTransformerBlockTransformer(num_tokens=len(token_to_id), d_model=dimension_model, max_len=max_len)\n",
    "transformer_model.to(device)\n",
    "optimizer = Adam(transformer_model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    transformer_model.train()\n",
    "    epoch_loss = 0\n",
    "    total_loss = 0\n",
    "    for data in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_tokens = batch['input_ids']\n",
    "        labels = batch['label']\n",
    "        input_tokens = input_tokens.to(device)  # Move inputs to GPU if available\n",
    "        labels = labels.to(device)  # Move labels to GPU if available\n",
    "        # Debugging: Ausgabe der maximalen und minimalen Werte von input_seq\n",
    "        #print(f\"Input Seq - Max Index: {input_seq.max().item()}, Min Index: {input_seq.min().item()}\")\n",
    "        #print(input_tokens.shape)\n",
    "        prediction = transformer_model(input_tokens)\n",
    "        #print(f\"Original Prediction shape: {prediction.shape}\")\n",
    "        #print(f\"Original Labels shape: {labels.shape}\")\n",
    "        labels = labels.view(-1)  # Flatten to [batch_size * seq_length]\n",
    "        #print(f\"labels views: {labels.shape}\")\n",
    "        #print(f\"Labels: {labels}\")\n",
    "\n",
    "        # Flatten prediction and labels\n",
    "        #prediction = prediction.view(-1, prediction.size(-1))  # [batch_size * seq_length, num_tokens]\n",
    "        #labels = labels.view(-1)  # [batch_size * seq_length]\n",
    "        #labels = torch.argmax(labels, dim=-1)\n",
    "        \n",
    "        #print(f\"Prediction shape: {prediction.shape}\")  # Should be [batch_size * seq_length, num_classes]\n",
    "        #print(f\"Labels shape: {labels.shape}\")          # Should be [batch_size * seq_length]\n",
    "\n",
    "        predictions_reduced = torch.mean(prediction, dim=1) \n",
    "        #print(f\"predictions_reduced: {predictions_reduced.shape}\")     \n",
    "\n",
    "        lable_unsqueezed = labels.unsqueeze(-1).float()\n",
    "        #print(f\"lable_unsqueezed: {lable_unsqueezed.shape}\")     \n",
    "        #loss = criterion(prediction, labels)\n",
    "        loss = criterion(predictions_reduced, lable_unsqueezed)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * input_tokens.size(0)\n",
    "        epoch_loss += loss.item()\n",
    "    scheduler.step(epoch_loss)\n",
    "    average_loss = total_loss / len(train_dataloader.dataset)\n",
    "    print(f\"Epoch {epoch}, Train Loss: {average_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85fd0397-01b5-4c81-ab9a-23fe0a3b64d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Reduce the sequence dimension using mean or max (depending on your needs)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m predictions_reduced \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(\u001b[43mpredictions\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# or torch.max(predictions, dim=1)[0]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Apply the loss function\u001b[39;00m\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(predictions_reduced, labels\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# assuming 'predictions' is your transformer model's output with shape (32, 100, 1)\n",
    "# and 'labels' is your tensor of labels with shape (32,)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Reduce the sequence dimension using mean or max (depending on your needs)\n",
    "predictions_reduced = torch.mean(predictions, dim=1)  # or torch.max(predictions, dim=1)[0]\n",
    "\n",
    "# Apply the loss function\n",
    "loss = criterion(predictions_reduced, labels.unsqueeze(-1).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52d55bbd-c541-4315-af87-520cd6447da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mscho\\AppData\\Local\\Temp\\ipykernel_21296\\1332413963.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attention_percents = F.softmax(scaled_sims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.959506682651799\n",
      "Test Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "transformer_model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_tokens = batch['input_ids']\n",
    "        labels = batch['label']\n",
    "        input_tokens = input_tokens.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        prediction = transformer_model(input_tokens)\n",
    "        predictions_reduced = torch.mean(prediction, dim=1)\n",
    "        labels_unsqueezed = labels.unsqueeze(-1).float()\n",
    "\n",
    "        loss = criterion(predictions_reduced, labels_unsqueezed)\n",
    "        test_loss += loss.item() * input_tokens.size(0)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predicted_labels = torch.round(torch.sigmoid(predictions_reduced))\n",
    "        correct += (predicted_labels == labels_unsqueezed).sum().item()\n",
    "        total += input_tokens.size(0)\n",
    "\n",
    "average_test_loss = test_loss / len(test_dataloader.dataset)\n",
    "accuracy = correct / total\n",
    "\n",
    "print(f\"Test Loss: {average_test_loss}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "33f2b2fb-b26b-4c62-849b-e33343a02a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"text\": \"I love this product!\", \"label\": 1},\n",
    "    {\"text\": \"This product is terrible.\", \"label\": 0},\n",
    "    {\"text\": \"I'm so happy with this purchase!\", \"label\": 1},\n",
    "    {\"text\": \"I regret buying this.\", \"label\": 0},\n",
    "    {\"text\": \"This is the best thing I've ever bought!\", \"label\": 1},\n",
    "    {\"text\": \"I'm disappointed with this product.\", \"label\": 0},\n",
    "    {\"text\": \"I would definitely recommend this!\", \"label\": 1},\n",
    "    {\"text\": \"This is a waste of money.\", \"label\": 0},\n",
    "    {\"text\": \"I'm so impressed with this!\", \"label\": 1},\n",
    "    {\"text\": \"I don't like this at all.\", \"label\": 0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "78d9e187-a41a-4550-a472-c64eb33d4a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(texts, min_freq=1):\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        words = text.lower().split()\n",
    "        counter.update(words)\n",
    "    # Only keep words with a frequency greater than min_freq\n",
    "    vocab = {word: idx + 2 for idx, (word, freq) in enumerate(counter.items()) if freq >= min_freq}\n",
    "    vocab['<PAD>'] = 0\n",
    "    vocab['<UNK>'] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d14be83f-bf18-47b3-98bd-6855c2cefbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 2, 'love': 3, 'this': 4, 'product!': 5, 'product': 6, 'is': 7, 'terrible.': 8, \"i'm\": 9, 'so': 10, 'happy': 11, 'with': 12, 'purchase!': 13, 'regret': 14, 'buying': 15, 'this.': 16, 'the': 17, 'best': 18, 'thing': 19, \"i've\": 20, 'ever': 21, 'bought!': 22, 'disappointed': 23, 'product.': 24, 'would': 25, 'definitely': 26, 'recommend': 27, 'this!': 28, 'a': 29, 'waste': 30, 'of': 31, 'money.': 32, 'impressed': 33, \"don't\": 34, 'like': 35, 'at': 36, 'all.': 37, '<PAD>': 0, '<UNK>': 1}\n",
      "{'i': 2, 'love': 3, 'this': 4, 'product!': 5, 'product': 6, 'is': 7, 'terrible.': 8, \"i'm\": 9, 'so': 10, 'happy': 11, 'with': 12, 'purchase!': 13, 'regret': 14, 'buying': 15, 'this.': 16, 'the': 17, 'best': 18, 'thing': 19, \"i've\": 20, 'ever': 21, 'bought!': 22, 'disappointed': 23, 'product.': 24, 'would': 25, 'definitely': 26, 'recommend': 27, 'this!': 28, 'a': 29, 'waste': 30, 'of': 31, 'money.': 32, 'impressed': 33, \"don't\": 34, 'like': 35, 'at': 36, 'all.': 37, '<PAD>': 0, '<UNK>': 1}\n"
     ]
    }
   ],
   "source": [
    "texts = [sample['text'] for sample in data]\n",
    "vocab = build_vocab(texts)\n",
    "print(vocab)\n",
    "token_to_id = dataset.vocab\n",
    "print(token_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "000c7720-00b2-4163-9959-6a2b20bfe979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, data, vocab):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data[idx]['text']\n",
    "        label = self.data[idx]['label']\n",
    "\n",
    "        # Convert text to indices\n",
    "        indices = [self.vocab.get(word, self.vocab['<UNK>']) for word in text.lower().split()]\n",
    "\n",
    "        # Convert indices to tensor\n",
    "        input_ids = torch.tensor(indices)\n",
    "\n",
    "        # Convert label to tensor\n",
    "        label = torch.tensor(label)\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'label': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5d7afc-db75-4f05-adef-034645bf7d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SimpleDataset(data, vocab)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "for data in dataloader:\n",
    "    input_tokens = data['input_ids']\n",
    "    labels = data['label']\n",
    "    print(input_tokens)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cf2df6-970f-4af2-8d4a-d3415f41408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "max_len = 5\n",
    "token_to_id = dataset.vocab\n",
    "#print(token_to_id)\n",
    "id_to_token = dict(map(reversed, token_to_id.items()))\n",
    "print(len(token_to_id))\n",
    "\n",
    "#dimension_model = 768\n",
    "dimension_model = 256\n",
    "\n",
    "transformer_model = DecoderOnlyTransformerBlockTransformer(num_tokens=len(token_to_id), d_model=dimension_model, max_len=max_len)\n",
    "transformer_model.to(device)\n",
    "optimizer = Adam(transformer_model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    transformer_model.train()\n",
    "    epoch_loss = 0\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_tokens = data['input_ids']\n",
    "        labels = data['label']\n",
    "        input_tokens = input_tokens.to(device)  # Move inputs to GPU if available\n",
    "        labels = labels.to(device)  # Move labels to GPU if available\n",
    "        # Debugging: Ausgabe der maximalen und minimalen Werte von input_seq\n",
    "        #print(f\"Input Seq - Max Index: {input_seq.max().item()}, Min Index: {input_seq.min().item()}\")\n",
    "        #print(input_tokens.shape)\n",
    "        prediction = transformer_model(input_tokens)\n",
    "        labels = labels.view(-1)  # Flatten to [batch_size * seq_length]\n",
    "        predictions_reduced = torch.mean(prediction, dim=1)   \n",
    "        lable_unsqueezed = labels.unsqueeze(-1).float()\n",
    "        #print(f\"lable_unsqueezed: {lable_unsqueezed.shape}\")     \n",
    "        loss = criterion(predictions_reduced, lable_unsqueezed)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * input_tokens.size(0)\n",
    "        epoch_loss += loss.item()\n",
    "    scheduler.step(epoch_loss)\n",
    "    average_loss = total_loss / len(dataloader.dataset)\n",
    "    print(f\"Epoch {epoch}, Train Loss: {average_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6b40a4-1860-4ea0-9881-331a01ad3550",
   "metadata": {},
   "source": [
    "## Using simple data for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c2950dec-b8f2-4856-aa99-a89d9df7c2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "992483fe-94db-47b2-82cd-36bba9f7cb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a8e32f98-705e-42ba-adf6-41620a4fded9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 4, 3],\n",
       "        [2, 1, 0, 4, 3]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_id = {'what' : 0 ,'is' : 1 ,'statquest' : 2 ,'awesome' : 3 ,'<EOS>' : 4}\n",
    "id_to_token = dict(map(reversed, token_to_id.items()))\n",
    "inputs = torch.tensor([[token_to_id['what'],token_to_id['is'], token_to_id['statquest'], \n",
    "                        token_to_id['<EOS>'], token_to_id['awesome']],\n",
    "                       [token_to_id['statquest'],token_to_id['is'], token_to_id['what'], \n",
    "                        token_to_id['<EOS>'], token_to_id['awesome']]])\n",
    "labels = torch.tensor([[token_to_id['is'],token_to_id['statquest'], token_to_id['<EOS>'], \n",
    "                        token_to_id['awesome'], token_to_id['<EOS>']],\n",
    "                       [token_to_id['is'],token_to_id['what'], token_to_id['<EOS>'], \n",
    "                        token_to_id['awesome'], token_to_id['<EOS>']]])\n",
    "dataset = TensorDataset(inputs, labels)\n",
    "dataloader = DataLoader(dataset)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "77cb2f17-f199-435b-89ca-203df319175b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 4, 3, 4],\n",
       "        [1, 0, 4, 3, 4]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.tensor([[token_to_id['is'],token_to_id['statquest'], token_to_id['<EOS>'], \n",
    "                        token_to_id['awesome'], token_to_id['<EOS>']],\n",
    "                       [token_to_id['is'],token_to_id['what'], token_to_id['<EOS>'], \n",
    "                        token_to_id['awesome'], token_to_id['<EOS>']]])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7d293dc0-3515-4b16-b090-08a949a02ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x212cb109be0>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TensorDataset(inputs, labels)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1c1f1dae-ec82-41e7-8509-abaa6dd31616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x212cb109460>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset)\n",
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "fdb07206-b855-4ba9-b0e4-a71ba0a9d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"text\": \"I love this product!\", \"label\": 1},\n",
    "    {\"text\": \"This product is terrible.\", \"label\": 0},\n",
    "    {\"text\": \"I'm so happy with this purchase!\", \"label\": 1},\n",
    "    {\"text\": \"I regret buying this.\", \"label\": 0},\n",
    "    {\"text\": \"This is the best thing I've ever bought!\", \"label\": 1},\n",
    "    {\"text\": \"I'm disappointed with this product.\", \"label\": 0},\n",
    "    {\"text\": \"I would definitely recommend this!\", \"label\": 1},\n",
    "    {\"text\": \"This is a waste of money.\", \"label\": 0},\n",
    "    {\"text\": \"I'm so impressed with this!\", \"label\": 1},\n",
    "    {\"text\": \"I don't like this at all.\", \"label\": 0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "157f9578-42c0-4f6c-8ec9-9fd4f6c7cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(texts, min_freq=1):\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        words = text.lower().split()\n",
    "        counter.update(words)\n",
    "    # Only keep words with a frequency greater than min_freq\n",
    "    vocab = {word: idx + 2 for idx, (word, freq) in enumerate(counter.items()) if freq >= min_freq}\n",
    "    vocab['<PAD>'] = 0\n",
    "    vocab['<UNK>'] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "5e4a41c3-e326-4236-82f5-aaa4de36ee4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 2, 'love': 3, 'this': 4, 'product!': 5, 'product': 6, 'is': 7, 'terrible.': 8, \"i'm\": 9, 'so': 10, 'happy': 11, 'with': 12, 'purchase!': 13, 'regret': 14, 'buying': 15, 'this.': 16, 'the': 17, 'best': 18, 'thing': 19, \"i've\": 20, 'ever': 21, 'bought!': 22, 'disappointed': 23, 'product.': 24, 'would': 25, 'definitely': 26, 'recommend': 27, 'this!': 28, 'a': 29, 'waste': 30, 'of': 31, 'money.': 32, 'impressed': 33, \"don't\": 34, 'like': 35, 'at': 36, 'all.': 37, '<PAD>': 0, '<UNK>': 1}\n"
     ]
    }
   ],
   "source": [
    "texts = [sample['text'] for sample in data]\n",
    "vocab = build_vocab(texts)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ad0a7fa1-cec2-4a81-911f-967e769aad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, data, vocab, min_len):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "        self.min_len = min_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #print(f\"idx: {idx}\")\n",
    "        #print(f\"self.data: {self.data}\")\n",
    "        text = self.data[idx]['text']\n",
    "        label = self.data[idx]['label']\n",
    "\n",
    "        # Convert text to indices\n",
    "        indices = [self.vocab.get(word, self.vocab['<UNK>']) for word in text.lower().split()]\n",
    "\n",
    "        if len(indices) < self.min_len:\n",
    "            indices += [0] * (self.min_len - len(indices))  # Use 0 instead of self.vocab['<PAD>']\n",
    "\n",
    "        # Convert indices to tensor\n",
    "        input_ids = torch.tensor(indices)\n",
    "\n",
    "        # Convert label to tensor\n",
    "        label = torch.tensor(label)\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'label': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a256c374-4b2e-43bf-b23c-99c8f0d58e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 2, 'love': 3, 'this': 4, 'product!': 5, 'product': 6, 'is': 7, 'terrible.': 8, \"i'm\": 9, 'so': 10, 'happy': 11, 'with': 12, 'purchase!': 13, 'regret': 14, 'buying': 15, 'this.': 16, 'the': 17, 'best': 18, 'thing': 19, \"i've\": 20, 'ever': 21, 'bought!': 22, 'disappointed': 23, 'product.': 24, 'would': 25, 'definitely': 26, 'recommend': 27, 'this!': 28, 'a': 29, 'waste': 30, 'of': 31, 'money.': 32, 'impressed': 33, \"don't\": 34, 'like': 35, 'at': 36, 'all.': 37, '<PAD>': 0, '<UNK>': 1}\n"
     ]
    }
   ],
   "source": [
    "dataset = SimpleDataset(data, vocab, 10)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "token_to_id = dataset.vocab\n",
    "print(token_to_id)\n",
    "for data in dataloader:\n",
    "    input_tokens = data['input_ids']\n",
    "    labels = data['label']\n",
    "    #print(input_tokens)\n",
    "    #print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc864be-a745-4553-9b0f-e9f7b37a16d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ab8dff67-8f88-47e8-9860-fe79a043a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(start=0, end=max_len, step=1).float().unsqueeze(1)\n",
    "        #print(position)\n",
    "        embedding_index = torch.arange(start=0, end=d_model, step=2).float()\n",
    "        #print(embedding_index)\n",
    "        div_term = 1 / torch.tensor(10000.0)**(embedding_index / d_model)\n",
    "        #print(div_term)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        #print(pe)\n",
    "        self.register_buffer('pe',pe)\n",
    "\n",
    "    def forward(self, word_embeddings):\n",
    "        #print(\"pe shape\")\n",
    "        #print(self.pe.shape)\n",
    "        #print(self.pe[:word_embeddings.size(0), :].shape)\n",
    "        #print(\"word embeddings shape\")\n",
    "        #print(word_embeddings.shape)\n",
    "        return word_embeddings + self.pe[:word_embeddings.size(0), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "963354ee-cc7d-4a41-9a57-1c57a971c12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PositionalEncoding()"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positionalEncoding = PositionalEncoding(d_model=2, max_len=10)\n",
    "positionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8aaa26eb-caec-4966-80c8-f37c90273070",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model=2):\n",
    "        super().__init__()\n",
    "        self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "        self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "        self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "        self.row_dim = 0\n",
    "        self.col_dim = 1\n",
    "\n",
    "    def forward(self, encodings, mask=None):\n",
    "        q = self.W_q(encodings)\n",
    "        k = self.W_k(encodings)\n",
    "        v = self.W_v(encodings)\n",
    "\n",
    "        # Ensure k has the same shape as q before transpose\n",
    "        assert k.shape == q.shape\n",
    "        \n",
    "        # Transpose k to align with q for dot product\n",
    "        k_transposed = k.transpose(-1, -2)\n",
    "        \n",
    "        # Check shapes\n",
    "        #print(\"Shape of q:\", q.shape)  # [1, 5, 2]\n",
    "        #print(q)\n",
    "        #print(\"Shape of k_transposed:\", k_transposed.shape)  # [1, 2, 5]\n",
    "        #print(k_transposed)\n",
    "        sims = torch.matmul(q, k_transposed)\n",
    "        scaled_sims = sims / torch.tensor(k.size(1)**0.5)\n",
    "\n",
    "        if mask is not None:\n",
    "            #mask = mask.to(device)\n",
    "            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n",
    "\n",
    "        attention_percents = F.softmax(scaled_sims)\n",
    "\n",
    "        attention_scores = torch.matmul(attention_percents, v)\n",
    "\n",
    "        return attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "87e08698-fc2b-48c5-869d-7f01ce790272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention(\n",
       "  (W_q): Linear(in_features=2, out_features=2, bias=False)\n",
       "  (W_k): Linear(in_features=2, out_features=2, bias=False)\n",
       "  (W_v): Linear(in_features=2, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = Attention(d_model=2)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e8d9b02c-b262-480e-9a0e-99d9a62a8a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderOnlyTransformer(nn.Module):\n",
    "\n",
    "    def __init__(self, num_tokens, d_model, max_len, using_mask=True):\n",
    "        super().__init__()\n",
    "        self.we = nn.Embedding(num_embeddings=num_tokens, embedding_dim=d_model)\n",
    "        self.pe = PositionalEncoding(d_model=d_model, max_len=max_len)\n",
    "        self.self_attention = Attention(d_model=d_model)\n",
    "        self.fc_layer = nn.Linear(in_features=d_model, out_features=1)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.using_mask = using_mask\n",
    "\n",
    "    def forward(self, token_ids):\n",
    "        # calculate word embeddings out of the tokens\n",
    "        word_embeddings = self.we(token_ids)\n",
    "        #print(word_embeddings)\n",
    "        # apply positional encoding (using the PositionalEncoder layer) to the word embeddings\n",
    "        position_encoded = self.pe(word_embeddings)\n",
    "        #print(position_encoded)\n",
    "        # create mask for decoder only transformer so it can not cheat\n",
    "        if (self.using_mask == True):\n",
    "            mask_ones = torch.ones((token_ids.size(dim=0), token_ids.size(dim=0)))\n",
    "            #print(mask_ones)\n",
    "            mask = torch.tril(mask_ones)\n",
    "            #print(mask)\n",
    "            mask = mask == 0\n",
    "            #print(mask)\n",
    "            # calculate self attention with the Attention Layer\n",
    "            self_attention_values = self.self_attention(position_encoded, mask=mask)\n",
    "        else:\n",
    "            self_attention_values = self.self_attention(position_encoded)    \n",
    "        # add original position_encoded values to the calculated self attention values (residual connection)\n",
    "        residual_connection_values = position_encoded + self_attention_values\n",
    "        # use the final linear layer to calculate the output probabilities\n",
    "        return self.fc_layer(residual_connection_values)\n",
    "        #fc_layer_output = self.fc_layer(residual_connection_values)\n",
    "        #return fc_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df256a2-474a-4dc5-87e8-974449e55c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 10\n",
    "transformer_model = DecoderOnlyTransformer(num_tokens=len(token_to_id), d_model=2, max_len=max_len, using_mask=False)\n",
    "optimizer = Adam(transformer_model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_tokens = data['input_ids']\n",
    "        labels = data['label']\n",
    "        reduced_tensor = input_tokens.squeeze()\n",
    "        prediction = transformer_model(reduced_tensor)\n",
    "\n",
    "        prediction = prediction.view(-1, prediction.size(-1))  # [batch_size * seq_length, num_tokens]\n",
    "        labels = labels.view(-1)  # [batch_size * seq_length\n",
    "        print(prediction)\n",
    "        print(labels)\n",
    "        loss = criterion(prediction, labels)  \n",
    "        \n",
    "        #reduced_tensor = prediction.view(-1)\n",
    "        #reduced_tensor = prediction.mean(dim=0)\n",
    "        #prediction = prediction.view(-1, prediction.size(-1))  # [batch_size * seq_length, num_tokens]\n",
    "        #labels = labels.view(-1).float()  # [batch_size * seq_length\n",
    "        #print(reduced_tensor)\n",
    "        #print(labels)\n",
    "        #loss = criterion(reduced_tensor, labels)        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * input_tokens.size(0)\n",
    "        epoch_loss += loss.item()\n",
    "    average_loss = total_loss / len(dataloader.dataset)\n",
    "    print(f\"Epoch {epoch}, Train Loss: {average_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "88f81330-4323-4779-9ff3-665588e43485",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedding = self.embedding(text)\n",
    "        layer1_output = self.fc1(embedding)\n",
    "        #print(layer1_output.shape)\n",
    "        pooled_output = layer1_output.mean(dim=1) \n",
    "        #print(pooled_output.shape)\n",
    "        dense_outputs = self.fc(pooled_output)\n",
    "        #output = F.log_softmax(dense_outputs, dim=1)\n",
    "        return dense_outputs\n",
    "        #print(output)\n",
    "        #return dense_outputs\n",
    "        # Apply a softmax for classification\n",
    "        #output = F.log_softmax(dense_outputs, dim=1)\n",
    "        #return output      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "9520c082-2b5b-42b6-ab5c-b5df4f3f6727",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRnnModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedding = self.embedding(text)\n",
    "        rnn_output, (hidden, cell) = self.rnn(embedding)\n",
    "        # hidden: [1, batch size, hidden dim] -> [batch size, hidden dim]\n",
    "        hidden = hidden[-1,:,:]\n",
    "        # Pass through the fully connected layer\n",
    "        print(hidden.shape)\n",
    "        pooled_output = hidden.mean(dim=1) \n",
    "        print(pooled_output)\n",
    "        dense_outputs = self.fc(pooled_output)\n",
    "        #dense_outputs = self.fc(hidden)\n",
    "        # Apply a softmax for classification\n",
    "        #output = F.log_softmax(dense_outputs, dim=1)\n",
    "        return dense_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "1766aa73-ad32-4d34-87b0-db89ca202915",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedding = self.embedding(text)\n",
    "        _, (hidden, _) = self.rnn(embedding)\n",
    "        #print(hidden.shape)\n",
    "        output = self.fc(hidden.squeeze(0))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "dfae8dfe-32cc-4cd9-b044-dcbf190e3ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentGRUModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedding = self.embedding(text)\n",
    "        _, hidden = self.rnn(embedding)\n",
    "        #print(hidden.shape)\n",
    "        output = self.fc(hidden.squeeze(0))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "f66de1e6-3ba5-4694-8a21-d062d556bb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "Epoch 0, Train Loss: 1.4191549837589263\n",
      "Epoch 1, Train Loss: 0.7171775668859481\n",
      "Epoch 2, Train Loss: 0.1341601110994816\n",
      "Epoch 3, Train Loss: 0.01307742353528738\n",
      "Epoch 4, Train Loss: 0.0027392345247790216\n",
      "Epoch 5, Train Loss: 0.001157200790476054\n",
      "Epoch 6, Train Loss: 0.0007865868101362139\n",
      "Epoch 7, Train Loss: 0.0006510086066555231\n",
      "Epoch 8, Train Loss: 0.0005742598848883062\n",
      "Epoch 9, Train Loss: 0.0005227021523751318\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(dataset.vocab)\n",
    "print(vocab_size)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "output_dim = 1\n",
    "\n",
    "sentiment_model = SentimentModel(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
    "#sentiment_model = SentimentRnnModel(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
    "#sentiment_model = SentimentLSTMModel(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
    "sentiment_model = SentimentGRUModel(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
    "optimizer = Adam(sentiment_model.parameters(), lr=0.01)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "sentiment_model.train()\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_tokens = data['input_ids']\n",
    "        #print(f\"input_ids: {input_tokens}\")\n",
    "        labels = data['label']\n",
    "        prediction = sentiment_model(input_tokens).squeeze(1)\n",
    "        labels = labels.view(-1).float()  # [batch_size * seq_length\n",
    "        #print(prediction)\n",
    "        #print(labels)\n",
    "        loss = criterion(prediction, labels) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * input_tokens.size(0)\n",
    "        epoch_loss += loss.item()\n",
    "    average_loss = total_loss / len(dataloader.dataset)\n",
    "    print(f\"Epoch {epoch}, Train Loss: {average_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "64ffda66-bdb4-4ca8-91ed-daa98a3fba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datas = [\n",
    "    {\"text\": \"I love this product!\", \"label\": 1},\n",
    "    {\"text\": \"This product is terrible.\", \"label\": 0},\n",
    "    {\"text\": \"I'm so happy with this purchase!\", \"label\": 1},\n",
    "    {\"text\": \"I regret buying this.\", \"label\": 0},\n",
    "    {\"text\": \"This is the best thing I've ever bought!\", \"label\": 1},\n",
    "    {\"text\": \"I'm disappointed with this product.\", \"label\": 0},\n",
    "    {\"text\": \"I would definitely recommend this!\", \"label\": 1},\n",
    "    {\"text\": \"This is a waste of money.\", \"label\": 0},\n",
    "    {\"text\": \"I'm so impressed with this!\", \"label\": 1},\n",
    "    {\"text\": \"I don't like this at all.\", \"label\": 0},\n",
    "    {\"text\": \"I don't like it.\", \"label\": 0},\n",
    "    {\"text\": \"I love this.\", \"label\": 1},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "cbd6fe1e-87cf-4d70-b7c3-f21d28cb263a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I love this product!', 'This product is terrible.', \"I'm so happy with this purchase!\", 'I regret buying this.', \"This is the best thing I've ever bought!\", \"I'm disappointed with this product.\", 'I would definitely recommend this!', 'This is a waste of money.', \"I'm so impressed with this!\", \"I don't like this at all.\", \"I don't like it.\", 'I love this.']\n"
     ]
    }
   ],
   "source": [
    "test_texts = [sample['text'] for sample in test_datas]\n",
    "print(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "1dddf8c9-4b89-43f5-867b-7d8d550bb3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love this product! - test_label: 1, binary predition: tensor([1]), test_prediction: tensor([7.5183], grad_fn=<SqueezeBackward1>)\n",
      "This product is terrible. - test_label: 0, binary predition: tensor([0]), test_prediction: tensor([-7.7729], grad_fn=<SqueezeBackward1>)\n",
      "I'm so happy with this purchase! - test_label: 1, binary predition: tensor([1]), test_prediction: tensor([7.4441], grad_fn=<SqueezeBackward1>)\n",
      "I regret buying this. - test_label: 0, binary predition: tensor([0]), test_prediction: tensor([-8.0550], grad_fn=<SqueezeBackward1>)\n",
      "This is the best thing I've ever bought! - test_label: 1, binary predition: tensor([1]), test_prediction: tensor([7.2929], grad_fn=<SqueezeBackward1>)\n",
      "I'm disappointed with this product. - test_label: 0, binary predition: tensor([0]), test_prediction: tensor([-7.2352], grad_fn=<SqueezeBackward1>)\n",
      "I would definitely recommend this! - test_label: 1, binary predition: tensor([1]), test_prediction: tensor([7.5731], grad_fn=<SqueezeBackward1>)\n",
      "This is a waste of money. - test_label: 0, binary predition: tensor([0]), test_prediction: tensor([-7.8854], grad_fn=<SqueezeBackward1>)\n",
      "I'm so impressed with this! - test_label: 1, binary predition: tensor([1]), test_prediction: tensor([7.6366], grad_fn=<SqueezeBackward1>)\n",
      "I don't like this at all. - test_label: 0, binary predition: tensor([0]), test_prediction: tensor([-7.9720], grad_fn=<SqueezeBackward1>)\n",
      "I don't like it. - test_label: 0, binary predition: tensor([0]), test_prediction: tensor([-4.5997], grad_fn=<SqueezeBackward1>)\n",
      "I love this. - test_label: 1, binary predition: tensor([0]), test_prediction: tensor([-4.3743], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "min_len = 10\n",
    "for test_data in test_datas:\n",
    "    #print(test_text)\n",
    "    test_input_text = test_data['text']\n",
    "    test_label = test_data['label']\n",
    "    #print(test_input_text)\n",
    "    #print(test_label)\n",
    "    test_indices = [vocab.get(word, vocab['<UNK>']) for word in test_input_text.lower().split()]\n",
    "    if len(test_indices) < min_len:\n",
    "        test_indices += [0] * (min_len - len(test_indices))  # Use 0 instead of self.vocab['<PAD>']\n",
    "    test_input_ids = torch.tensor(test_indices)\n",
    "\n",
    "    # Convert label to tensor\n",
    "    test_label = torch.tensor(test_label)\n",
    "    #print(test_input_ids)\n",
    "    #print(test_label)\n",
    "\n",
    "    # Adding a new dimension at the beginning to change the shape to [1, 10]\n",
    "    reshaped_test_input_ids = test_input_ids.unsqueeze(0)\n",
    "\n",
    "    #print(f\"Original Tensor shape: {test_input_ids.shape}\")  # Output: torch.Size([10])\n",
    "    #print(f\"Reshaped Tensor shape: {reshaped_test_input_ids.shape}\")  # Output: torch.Size([1, 10])\n",
    "    #print(reshaped_test_input_ids)\n",
    "    \n",
    "    test_prediction = sentiment_model(reshaped_test_input_ids).squeeze(1)\n",
    "    threshold = 0\n",
    "    binary_prediction = (test_prediction >= threshold).long()\n",
    "    print(f\"{test_input_text} - test_label: {test_label}, binary predition: {binary_prediction}, test_prediction: {test_prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c32108-35e1-4b58-ad1d-dbc66ae6a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_tokens = \n",
    "prediction = sentiment_model(test_input_tokens).squeeze(1)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
